{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import ast\n",
    "import pyperclip\n",
    "import pprint\n",
    "import os\n",
    "from together import Together\n",
    "import os \n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "\n",
    "\n",
    "client = Together(api_key=open('/Users/spangher/.togetherai-usc-key.txt').read().strip())\n",
    "def query_together(prompt, client=client):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo\",\n",
    "        messages=[{\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are an experienced journalist.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                }],\n",
    "        max_tokens=2048,\n",
    "        temperature=0.1,\n",
    "        top_p=0.7,\n",
    "        top_k=50,\n",
    "        repetition_penalty=1,\n",
    "        stop=[\"<|eot_id|>\",\"<|eom_id|>\"],\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEAN_ARTICLE_TEXT_PROMPT = \"\"\"\n",
    "You are a helpful editor assistant. I scraped this news article from the web and removed HTML tags, however, \n",
    "there is a lot of extraneous text from the HTML page that remains. Please only extract text related to the news article.\n",
    "Do NOT miss any article text. Here is the news article:\n",
    "\n",
    "```{article_text}```\n",
    "\n",
    "Return only the CLEANED text of the news article, nothing else.\n",
    "\"\"\"\n",
    "\n",
    "DISCOURSE_PROMPT = \"\"\"\n",
    "You will receive a sentence from a {document_type}. Your task is to identify the structural role that this sentence plays in the overall {document_type}.\n",
    "Please generate a generalizable keyword label to describe the structural role. The label must be as generalizable as possible and should not be document-specific. \n",
    "\n",
    "{definitions}\n",
    "\n",
    "For reference, I'll also give you the full {document_type}.\n",
    "\n",
    "[Examples]\n",
    "Example 1:\n",
    "\n",
    "Sentence: \"This annual festival, which welcomes and celebrates large, gay men -- 'bears' -- on the tip of Cape Cod, ended Saturday.\"\n",
    "Your response: \n",
    "\"Main Event\": This sentence directly describes a primary event, noting its conclusion, which is the focal point of the document.\n",
    "\n",
    "Example 2:\n",
    "Sentence: \"But the league has also become one of the most prestigious summer internships for aspiring broadcasters.\"\n",
    "Your response:\n",
    "\"Current Context\": This sentence explains the background that contributes to the league's reputation, making it a relevant aspect of the broader discussion within the document.\n",
    "\n",
    "[Instructions]\n",
    "Again, determine a generalizable structure labels in the document.\n",
    "\n",
    "Each keyword label must reflect a SINGLE structural feature instead of a combination of features.\n",
    "If you add a new label, add a SHORT GENERAL LABEL and a DESCRIPTION OF THAT LABEL.\n",
    "If the sentence is an error, return \"Error\". \n",
    "Return in the same format as the examples: \"LABEL\": DESCRIPTION. Please feel free to add a new label if it helps describe a sentence.\n",
    "\n",
    "Now it's your turn. Here's a {document_type}:\n",
    "\n",
    "[{document_type}]\n",
    "```{document}```\n",
    "\n",
    "What role does the following sentence play in the {document_type}?\n",
    "\n",
    "[Sentence]\n",
    "```{sentence}```\n",
    "\n",
    "Please only state your response as \"LABEL\": DESCRIPTION. Say nothing else.\"\"\"\n",
    "\n",
    "SOURCE_EXTRACTION_PROMPT = \"\"\"\n",
    "You are a helpful news assistant. Here is a news article:\n",
    "\n",
    "```{news_article}```\n",
    "\n",
    "Please summarize each informational source providing information in the article. \n",
    "Include unnamed or passively expressed sources (e.g. \"witnesses\", \"price signals\") if there is information attributable to them.\n",
    "Include any facts that might have come from the source.\n",
    "Make sure each source you return refer to just one source. For example: if \"John and Jane\" both contribute the same information, generate two separate summaries, one for \"John\" and one for \"Jane\". \n",
    "Generate only ONE summary per source.\n",
    "\n",
    "For each source, provide the following information:\n",
    "    (1) Name: just the name of the source.\n",
    "    (2) Biography: A brief biography of the source mentioned in the article.\n",
    "    (3) Information: Restate the facts provided by the source. Be as SPECIFIC and be as VERBOSE as possible. \n",
    "        Contextualize ALL the information the source describes. State the full names of all people, places, events and ideas mentioned and\n",
    "        everything the source says with AS MUCH BACKGROUND INFORMATION from the article so I can fully understand the information\n",
    "        the source is giving. I will look at each source independently without looking at any others, so help me understand the context.\n",
    "\n",
    "Here are some examples:\n",
    "example 1:\n",
    "{{ \"Name\": \"Supermarkets around the country\",\n",
    "   \"Biography\": \"Retail stores that sell food and other household items\",\n",
    "   \"Information\": \"Supermarkets around the country alerted shoppers that prices are likely to continue going up due to the avian flu outbreak, with eggs now average $2.88 per dozen, up 52% since the first confirmed case of avian influenza in February.\"\n",
    "}}\n",
    "\n",
    "example 2:\n",
    "{{\n",
    "  \"Name\": \"The article's author (unnamed)\",\n",
    "  \"Biography\": \"The author of the article\",\n",
    "  \"Information\": \"The author stated that Wing, which is collaborating with FedEx and Walgreens on drone delivery, was the first to receive a limited Part 135 certificate. Wing is launching operations in Virginia this month, and the Standard certification allows UPS to send an unlimited number of drones to the skies, for their cargo load to exceed 55 pounds and for them to fly at night.\"\n",
    "}}\n",
    "\n",
    "example 3:\n",
    "{{\n",
    "   \"Name\": \"Delta's customers\",\n",
    "   \"Biography\": \"People who travel with Delta Air Lines\",\n",
    "   \"Information\": \"Delta's customers suggested that they preferred more space on flights amid the COVID-19 pandemic, and they continue to tell Delta that more space provides more peace of mind.\"\n",
    "}}\n",
    "\n",
    "example 4:\n",
    "{{\n",
    "   \"Name\": \"European Union countries\",\n",
    "   \"Biography\": \"Countries that are part of the European Union\",\n",
    "   \"Information\": \"European Union countries are working on adopting copyright rules that allow news companies and publishers to negotiate payments with large tech companies like Facebook, Microsoft and Google that use their content on their platforms.\"\n",
    "}}\n",
    "\n",
    "Output the summary in a list of python dictionaries as in the examples. Don't say anything else.\n",
    "\"\"\"\n",
    "\n",
    "NARRATIVE_KEYWORD_PROMPT = \"\"\"\n",
    "You will receive a news article and a set of sources to examine in that article.\n",
    "\n",
    "For each source in the list, provide the following information, once per source:\n",
    "    (1) Name: Exactly copy the name of the source.\n",
    "    (2) Narrative Function: Give a generic keyword label to categorize the narrative role the source playes in the article. \n",
    "    Infer why the author used the source, and a generalizable statement about the role they play in the article.\n",
    "    Don't just summarize their identity. Return in the format: \"LABEL\": DESCRIPTION.\n",
    "\n",
    "Here are example outputs. Again, your main task here is to identify a generalizable label that can characterize the narrative role of each source and why the author used them. \n",
    "\n",
    "[Examples]\n",
    "Example 1:\n",
    "\n",
    "{{\n",
    "    \"Name\": \"Match Group\",\n",
    "    \"Narrative Function\": \"\\\"Counterpoint\\\": This source is used to compare to the main actor in the news article and provide grounding.\"\n",
    "}}\n",
    "\n",
    "Example 2:\n",
    "\n",
    "{{\n",
    "    \"Name\": \"Dubai Airshow\",\n",
    "    \"Narrative Function\": \"\\\"More Context\\\": This source is used to further expand the context offered and offer a visual setting.\"\n",
    "}}\n",
    "\n",
    "Example 3:\n",
    "{{\n",
    "\n",
    "    \"Name\": \"Ann Gough\",\n",
    "    \"Narrative Function\": \"\\\"Victim\\\": This source provides the voice of a user for the product, giving us a personal view of the harm caused by the event.\n",
    "}}\n",
    "\n",
    "[Instructions]\n",
    "\n",
    "Now it's your turn. Here is a news article:\n",
    "\n",
    "```{news_article}```\n",
    "\n",
    "Please examine the narrative role of each of the following sources: \n",
    "\n",
    "```[{target_sources}]```\n",
    "\n",
    "For each source, answer the questions above. Output the summary in a list of python dictionaries as in the examples. Don't say anything else.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "CENTRALITY_AND_PERSPECTIVE_PROMPT = \"\"\"\n",
    "You will receive a news article and a set of sources to examine in that article.\n",
    "    \n",
    "    For each source, provide the following information:\n",
    "        (1) Name: who the source is.\n",
    "        (2) Perspective: What is their perspective on the main events of the article? Choose as many labels as fit from: [\"Authoritative\", \"Informative\", \"Supportive\", \"Skeptical\", \"Against\", \"Neutral\"].\n",
    "        (3) Centrality: How central is this source to the main events of the article? Choose from \"High\", \"Medium\", \"Low\".\n",
    "        (4) Is_Error: Did we annotate this source in error? This can happen for many reasons, including if a sentence from the webpage was included in the story unintentionally. Answer with \"Yes\" or \"No\".\n",
    "\n",
    "Here is a news article:\n",
    "\n",
    "```{news_article}```\n",
    "\n",
    "Please examine the role of each of the following sources: \n",
    "\n",
    "```[{target_sources}]```\n",
    "\n",
    "For each source, answer the questions above. Output the summary in a list of python dictionaries as in the examples. Don't say anything else.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def robust_parse_narr_json_str(t):\n",
    "    t = t.replace(']','').replace('[','').replace('`', '').strip()\n",
    "    t2_chunks = re.split(r'\\},\\s+\\{', t)\n",
    "    \n",
    "    all_ds = []\n",
    "    for t2 in t2_chunks:\n",
    "        d = {}\n",
    "        t3_chunks = t2.replace('{', '').replace('}', '').strip().split('\\n')\n",
    "        for t3 in t3_chunks:\n",
    "            if 'Name' in t3:\n",
    "                d['Name'] = t3.replace('\"Name\":', '').strip().removeprefix('\"').removesuffix('\",')\n",
    "            if 'Narrative Function' in t3:\n",
    "                d['Narrative Function'] = t3.replace('\"Narrative Function\":', '').strip()\n",
    "        all_ds.append(d)\n",
    "    return all_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "# spacy pipeline\n",
    "def sentence_splitting_pipeline(texts):    \n",
    "    docs = nlp.pipe(texts)\n",
    "    # Extract sentences from each processed document\n",
    "    sentences_list = [[sent.text for sent in doc.sents] for doc in docs]\n",
    "    return sentences_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student Writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "student_article_df = pd.read_csv('../data/batch_article_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/2024/10/08/dream-big-says-ezra-frech-a-two-time-paralympic-gold-medalist/'"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_article_df.iloc[0]['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_prompt = CLEAN_ARTICLE_TEXT_PROMPT.format(article_text=student_article_df['article_text'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_article_text = query_together(clean_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_by_doc = sentence_splitting_pipeline([student_article_text])\n",
    "sentences_by_doc = list(map(lambda x: x.strip().replace('\\n', ' '), sentences_by_doc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyperclip.copy('\\n'.join(sentences_by_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3477833e5d634670964d48aa59e37866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "responses = []\n",
    "for s in tqdm(sentences_by_doc):\n",
    "    prompt = DISCOURSE_PROMPT.format(document_type='news article', definitions='', document='\\n'.join(sentences_by_doc), sentence=s)\n",
    "    responses.append(query_together(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyperclip.copy('\\n'.join(list(map(lambda x: x.split(':')[0], responses))))\n",
    "pyperclip.copy('\\n'.join(list(map(lambda x: x.split(':')[1], responses))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = SOURCE_EXTRACTION_PROMPT.format(news_article='\\n'.join(sentences_by_doc))\n",
    "r = query_together(prompt=prompt)\n",
    "source_df = pd.DataFrame(json.loads(r))\n",
    "prompt = NARRATIVE_KEYWORD_PROMPT.format(news_article='\\n'.join(sentences_by_doc), target_sources=', '.join(source_df['Name'].tolist()))\n",
    "narr_r = query_together(prompt=prompt)\n",
    "narr_df = pd.DataFrame(robust_parse_narr_json_str(narr_r))\n",
    "prompt = CENTRALITY_AND_PERSPECTIVE_PROMPT.format(news_article='\\n'.join(sentences_by_doc), target_sources=', '.join(source_df['Name'].tolist()))\n",
    "cent_r = query_together(prompt=prompt)\n",
    "cent_df = pd.DataFrame(json.loads(cent_r.replace('`python\\n', '').replace('`', '')))\n",
    "full_ex_df = source_df.merge(narr_df, on='Name').merge(cent_df, on='Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_ex_df.to_csv('cache/student_ex_source_df_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Match with a professional article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "professional_article_text_files = glob.glob('../../../berkeley-research/conditional-information-retrieval/data/v3_sources/v3_source_summaries/*article_text*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = list(map(lambda x: pd.read_json(x, lines=True), professional_article_text_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_file_df = pd.concat(all_files).sample(50_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "824151f31cbb4ccba77886630ae956ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1563 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2. Calculate embeddings by calling model.encode()\n",
    "embeddings = model.encode(full_file_df['response'].tolist(), show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match professional articles with student articles \n",
    "sample_emb = model.encode(['\\n'.join(sentences_by_doc)])\n",
    "cos_sims = cosine_similarity(sample_emb, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_professional_article = full_file_df.iloc[np.argmax(cos_sims)]\n",
    "sample_professional_text = sample_professional_article['response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyperclip.copy(sample_professional_article['url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_by_doc = sentence_splitting_pipeline([sample_professional_text])\n",
    "sentences_by_doc = list(map(lambda x: x.strip().replace('\\n', ' '), sentences_by_doc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyperclip.copy('\\n'.join(sentences_by_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "974454f44d574e5cb35373948673c3ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "responses = []\n",
    "for s in tqdm(sentences_by_doc):\n",
    "    prompt = DISCOURSE_PROMPT.format(document_type='news article', definitions='', document='\\n'.join(sentences_by_doc), sentence=s)\n",
    "    responses.append(query_together(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyperclip.copy('\\n'.join(list(map(lambda x: x.split(':')[0], responses))))\n",
    "pyperclip.copy('\\n'.join(list(map(lambda x: x.split(':')[1], responses))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = SOURCE_EXTRACTION_PROMPT.format(news_article='\\n'.join(sentences_by_doc))\n",
    "r = query_together(prompt=prompt)\n",
    "source_df = pd.DataFrame(json.loads(r))\n",
    "prompt = NARRATIVE_KEYWORD_PROMPT.format(news_article='\\n'.join(sentences_by_doc), target_sources=', '.join(source_df['Name'].tolist()))\n",
    "narr_r = query_together(prompt=prompt)\n",
    "narr_df = pd.DataFrame(robust_parse_narr_json_str(narr_r))\n",
    "prompt = CENTRALITY_AND_PERSPECTIVE_PROMPT.format(news_article='\\n'.join(sentences_by_doc), target_sources=', '.join(source_df['Name'].tolist()))\n",
    "cent_r = query_together(prompt=prompt)\n",
    "cent_df = pd.DataFrame(json.loads(cent_r.replace('`python\\n', '').replace('`', '')))\n",
    "full_ex_df = source_df.merge(narr_df, on='Name').merge(cent_df, on='Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_ex_df.to_csv('cache/professional_ex_source_df_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Professional Writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file_name = \"../../../berkeley-research/conditional-information-retrieval/data/v3_sources/v3_source_summaries/test_sources__article_text__0_500.txt\"\n",
    "text_df = pd.read_json(sample_file_name, lines=True)\n",
    "text_df = (text_df\n",
    " .loc[lambda df: ~df['response'].str.contains('python', case=False)]\n",
    " .loc[lambda df: ~df['response'].str.contains('<div', case=False)]\n",
    " .assign(response=lambda df: df['response'].str.replace('`', '').str.replace(r'<[^>]*>', '').str.strip())\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To mark Suicide Awareness Month, a team of researchers set out to determine who teens turn to when faced with mental health concerns. by Gianna Melillo | Sep. 08, 2022 Story at a glance More educators than parents report being approached by young adults with mental health concerns. Findings of the new survey underscore the important role teachers and educators can play in promoting youth mental health. In an effort to improve access to care, the Biden Administration has allotted nearly $300 million to bolster mental health resources in schools. New data suggests teens reach out to educators more than their parents about mental health concerns, while experts stress both adults can play complementary roles in supporting young people's mental health. Most educators, 78 percent, have been approached by a child about a mental or emotional concern, according to a CVS Health/Morning Consult survey published Thursday. That's compared to 58 percent of parents who report the same, underscoring how a network of adults can help young people navigate their mental health. More than three-quarters of educators say they are concerned about adolescents' mental health, compared to 43 percent of parents who say the same. Nearly half of parents surveyed say they had initiated a mental health conversation with their child, while 22 percent of educators report ever doing so. America is changing faster than ever! Add Changing America to your Facebook or Twitter feed to stay on top of the news. The poll was conducted online in August 2022 among 500 parents and 340 educators of teens between the ages 13 and 17. The results come as children and adolescents face increasing mental health concerns, exacerbated by the COVID-19 pandemic. Around 1.5 million more kids experienced depression or anxiety in 2021, prompting U.S. Surgeon General Vivek Murthy to issue an advisory in December. \"Mental health challenges in children, adolescents, and young adults are real and widespread,\" Murthy said, adding that \"the future wellbeing of our country depends on how we support and invest in the next generation.\" When asked about top stressors teens face today, educators overwhelmingly cited family dynamics and relationships, self-esteem, bullying and social dynamics, along with social media usage. In comparison, parents were more likely to cite academic pressure, self-esteem and pandemic-related stress as top negative mental health influences. More than 70 percent of educators also say issues relating to gender, race and sexuality were factors relating to teens' negative mental health compared with just one-quarter of parents. Both cohorts agreed the most beneficial resource to bolster teen mental health is more affordable mental health care. This is a priority for President Biden, who in July announced a nearly $300 million allotment to expand access to mental health care in schools. Despite increasing popularity for mental health days, where children do not attend school to focus on their well-being, only 12 states allow the practice. At the same time, barriers like social stigma and economic challenges may prevent more schools from taking up the practice. Related Content Despite growing popularity, school mental health days are only allowed in these 12 states View How mobile psychiatrists can help the unhoused View Unpaid work takes a toll on employed women's mental health View Psychiatrists disagree with US policy on certain psychoactive drugs: survey View Here’s why kids shouldn’t skip breakfast View As children turn to adults in many aspects of their lives for mental health support, both parents and educators say they feel equipped to help. An equal percentage of parents and educators report they would know where to find support for a young person, according to the survey. Both also say they would speak directly to the child, to one another or seek help from a professional. \"Young people continue to face a mental health crisis, but they are not facing it alone,\" said CVS Health President and Chief Executive Officer Karen S. Lynch in a press release. \"Mental health can, and should, become a part of everyday conversation in the classroom, during lunch hour and at the dinner table.\"\n"
     ]
    }
   ],
   "source": [
    "sample_text = (\n",
    "    text_df['response']\n",
    "               .pipe(lambda df: \n",
    "                     df.iloc[1]\n",
    "                     .split('Here is the cleaned-up text:')[1]\n",
    "                     .split('I removed the extraneous text from the news article')[0]\n",
    "                     .strip()\n",
    "               ))\n",
    "print(sample_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News Discourse Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_by_doc = sentence_splitting_pipeline([sample_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd72244a8d4343539926440e0ae43f61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "responses = []\n",
    "for s in tqdm(sentences_by_doc[0]):\n",
    "    prompt = DISCOURSE_PROMPT.format(document_type='news article', definitions='', document=sample_text, sentence=s)\n",
    "    responses.append(query_together(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyperclip\n",
    "pyperclip.copy('\\n'.join(sentences_by_doc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyperclip.copy('\\n'.join(list(map(lambda x: x.split(':')[1], responses))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Source Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_source_file_name = \"../../../berkeley-research/conditional-information-retrieval/data/v3_sources/v3_source_summaries/test_sources__summaries__0_500.txt\"\n",
    "sample_source_centrality_name = \"../../../berkeley-research/conditional-information-retrieval/data/v3_sources/v3_source_summaries/test_sources__centrality-perspective__0_500.txt\"\n",
    "sample_source_narrative_keyword_file_name = \"../../../berkeley-research/conditional-information-retrieval/data/v3_sources/v3_source_summaries/test_sources__narrative-keyword__0_500.txt\"\n",
    "source_summary_df = pd.read_json(sample_source_file_name, lines=True)\n",
    "source_centrality_df = pd.read_json(sample_source_centrality_name, lines=True)\n",
    "source_narrative_keyword_df = pd.read_json(sample_source_narrative_keyword_file_name, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "source_example_df = pd.DataFrame(json.loads(source_summary_df.loc[3]['response'].split('Here is the list of sources:')[1].replace('`', '')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "centrality_df = pd.DataFrame(json.loads(source_centrality_df.loc[3]['response'].replace('`', '')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "narr_func_str = [{\n",
    "    \"Name\": \"U.S. Surgeon General Vivek Murthy\",\n",
    "    \"Narrative Function\": '''\"Expert\": This source is used to provide a quote from an expert in the field, adding credibility to the article and providing a statement about the severity of the issue.'''\n",
    "},\n",
    "{\n",
    "    \"Name\": \"CVS Health President and Chief Executive Officer Karen S. Lynch\",\n",
    "    \"Narrative Function\": '''\"Counterpoint\": This source is used to provide a quote from a business leader, adding a counterpoint to the article and providing a statement about the importance of mental health in everyday life.'''\n",
    "},\n",
    "{\n",
    "    \"Name\": \"Educators\",\n",
    "    \"Narrative Function\": '''\"Data\": This source is used to provide data about educators' experiences and perspectives on mental health, adding a quantitative element to the article and providing evidence for the importance of educators in supporting young people's mental health.'''\n",
    "},\n",
    "{\n",
    "    \"Name\": \"Parents\",\n",
    "    \"Narrative Function\": '''\"Data\": This source is used to provide data about parents' experiences and perspectives on mental health, adding a quantitative element to the article and providing evidence for the importance of parents in supporting young people's mental health.'''\n",
    "},\n",
    "{\n",
    "    \"Name\": \"The Biden Administration\",\n",
    "    \"Narrative Function\": '''\"Solution\": This source is used to provide information about a solution to the problem of mental health in schools, adding a sense of hope and action to the article and providing evidence for the importance of government support for mental health initiatives.'''\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "narr_funct_df = pd.DataFrame(narr_func_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyperclip.copy('\\n'.join(narr_funct_df['Narrative Function']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Narrative Function</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U.S. Surgeon General Vivek Murthy</td>\n",
       "      <td>\"Expert\": This source is used to provide a quo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CVS Health President and Chief Executive Offic...</td>\n",
       "      <td>\"Counterpoint\": This source is used to provide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Educators</td>\n",
       "      <td>\"Data\": This source is used to provide data ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Parents</td>\n",
       "      <td>\"Data\": This source is used to provide data ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Biden Administration</td>\n",
       "      <td>\"Solution\": This source is used to provide inf...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Name  \\\n",
       "0                  U.S. Surgeon General Vivek Murthy   \n",
       "1  CVS Health President and Chief Executive Offic...   \n",
       "2                                          Educators   \n",
       "3                                            Parents   \n",
       "4                           The Biden Administration   \n",
       "\n",
       "                                  Narrative Function  \n",
       "0  \"Expert\": This source is used to provide a quo...  \n",
       "1  \"Counterpoint\": This source is used to provide...  \n",
       "2  \"Data\": This source is used to provide data ab...  \n",
       "3  \"Data\": This source is used to provide data ab...  \n",
       "4  \"Solution\": This source is used to provide inf...  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "narr_funct_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "centrality_df\n",
    "pyperclip.copy('\\n'.join(centrality_df['Perspective']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyperclip.copy('\\n'.join(source_example_df['Information']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
